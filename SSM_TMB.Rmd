---
title: "Fitting state-space models using the R package TMB"
author: "Marie Auger-Methe"
date: "28/02/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Document info

This tutorial is heavily based on Appendix S1 (Supporting Information) from Auger-Méthé, M., Newman, K., Cole, D., Empacher, F., Gryba, R., King, A. A., Leos-Barajas, V., Mills Flemming, J., Nielsen, A., Petris, G., and Thomas, L.. 2021. A guide to state–space modeling of ecological time series. Ecological Monographs 91(4):e01470. 10.1002/ecm.1470 (Open access,  https://doi.org/10.1002/ecm.1470). Please refer to the paper and tutorial for more in-depth information on state-space models and how to apply them to data using R.

# Important installation info (to do before seminar!)

Because `TMB` use C++ code, the installation of the package requires additional steps. The package is available on CRAN https://cran.r-project.org/web/packages/TMB/index.html, however your computer needs to be set up so you can compile the C++ code. You can find installation information at: https://github.com/kaskr/adcomp/wiki/Download. Briefly, if you are Mac user, you will need to install the Xcode developer tools (freely available via the App store). With older versions of Mac OS, you may run into problems with the Fortran compiler. For solutions, see the link above and this link https://mac.r-project.org/tools/. If you are a Windows user, you will need to install Rtools: https://cran.r-project.org/bin/windows/Rtools/. You can find guidelines on how to install `TMB` on a Windows machine here: https://github.com/kaskr/adcomp/wiki/Windows-installation.


# Introducing the method with a simple univariate linear Gaussian state-space models

## Model

We start by exploring a very simple SSM: a simple linear SSM with Normal distributions. This model is not linked to an ecological example; it's just a teaching tool. This linear Gaussian SSM
consists of two equations for two time series.

The process equation (or state equation) is:
\begin{equation}
  z_t = \beta z_{t-1} + \epsilon_t, \;\;\; \epsilon_t \sim \text{N}(0, \sigma_p^2),
  \label{E.toy4p.p}
\end{equation}
where $z_t$ is the state value at time $t$, for $t=1, ..., T$ and $\beta$ represents the autocorrelation in the state values. The states are generally unknown, i.e., cannot be observed directly, and are sometimes referred to as latent states or hidden states. This equation represents the evolution of the hidden state as a correlated random walk. The equation implies that there is some stochasticity in the process. This stochasticity is often referred as process variation and is here described by a Normal (Gaussian) distribution with standard deviation $\sigma_p$. For simplicity, we set the initial state value to be 0, i.e., $z_0 =0$.

The observation equation (or measurement equation) is:
\begin{equation}
  y_t = \alpha z_{t} + \eta_t, \;\;\; \eta_t \sim \text{N}(0, \sigma_o^2),
  \label{E.toy4p.o}
\end{equation}
where $y_t$ is the observation at time $t$, for $t=1, ..., T$ and $\alpha$ is a constant of proportionality that represents any systematic discrepancy between the observations and the states (e.g., the average detection rate). This equation links the observation at time $t$ to the underlying state at that time. The equation implies that we are observing the process with error. This error term is often referred as the observation error and, here, is described by a Normal distribution with standard deviation $\sigma_o$.

This model has four parameters: $\alpha, \beta, \sigma_o, \sigma_p$. It is sometimes
difficult to accurately estimate all four parameters, something we will demonstrate in the sections below. It is useful to explore a simpler model, where we fix two of the parameters and only have two parameters to estimate. In the simpler model, we fix both $\alpha$ and $\beta$ to 1, resulting in the following.

The process equation is now:
\begin{equation}
  z_t = z_{t-1} + \epsilon_t, \;\;\; \epsilon_t \sim \text{N}(0, \sigma_p^2),
  \label{E.toy2p.p} 
\end{equation}
and represents the evolution of the hidden state as a simple random walk. The observation equation is now:
\begin{equation}
  y_t = z_{t} + \eta_t, \;\;\; \eta_t \sim \text{N}(0, \sigma_o^2),
  \label{E.toy2p.o}
\end{equation}
where we assume that there is no systematic bias in the observation (i.e. we observed the state with some error but the observations are not systematically smaller or larger than the states).

## Simulations

Here, we simulate data using the linear Gaussian SSM described in Eqs. \ref{E.toy2p.p}-\ref{E.toy2p.o} from section \ref{LGSSMm} above. This is the simpler model where two of the parameters are fixed ($\alpha=\beta=1$).

First, let us simulate the process for a time series of length 200 ($T=200$), with an additional time step for the state at $t=0$. To be consistent with the model description, we set to $z_0 = 0$. We choose the standard deviation of the process variation, $\sigma_p$, to be 0.1.

```{r process.sim, tidy=FALSE}
# Create a vector that will keep track of the states
# It's of length T + 1 (+1 for t=0)
# T is not a good name in R, because of T/F, so we use TT
TT <- 200
z <- numeric(TT + 1)
# Standard deviation of the process variation
sdp <- 0.1
# Set the seed, so we can reproduce the results
set.seed(553)
# For-loop that simulates the state through time, using i instead of t,
for(i in 1:TT){
  # This is the process equation
  z[i+1] <- z[i] + rnorm(1, 0, sdp)
  # Note that this index is shifted compared to equation in text,
  # because we assume the first value to be at time 0
}
```

Let us plot the time series we have created.

```{r process.sim.fig}
plot(0:TT, z,
     pch = 19, cex = 0.7, col="red", ty = "o", 
     xlab = "t", ylab = expression(z[t]), las=1)
```

Second, let us simulate the observations. We set the standard deviation of the observation error $\sigma_o$ to 0.1.

```{r obs.sim, tidy=FALSE}
# Create a vector that will keep track of the observations
# It's of length T
y <- numeric(TT)
# Standard deviation of the observation error
sdo <- 0.1
# For t=1, ... T, add measurement error
# Remember that z[1] is t=0
y <- z[2:(TT+1)] + rnorm(TT, 0, sdo)
```

Let us plot both the observations and the states. From now on, we are adding extra space on the y-axis to leave space for the legend. Note that the space we assigned may not work for all figure sizes.

```{r obs.sim.fig, tidy=FALSE}
plot(1:TT, y,
     pch=3, cex = 0.8, col="blue", ty="o", lty = 3,
     xlab = "t", ylab = expression(z[t]),
     xlim = c(0,TT), ylim = c(min(y), max(y)+max(y)/5),
     las = 1)
points(0:TT, z,
       pch = 19, cex = 0.7, col="red", ty = "o")
legend("top",
       legend = c("Obs.", "True states"),
       pch = c(3, 19),
       col = c("blue", "red"),
       lty = c(3, 1),
       horiz=TRUE, bty="n", cex=0.9)
```

With real data, we usually only have the observations, $y_t$, and do not know the true states, $z_t$. However, simulated data allow us to see the discrepancies between the observed values and the values for the process they represent.

## Fitting the model using TMB

In TMB you need to create a C++ file that computes the value of the negative log likelihood for your data and for a given set of parameter values. Then, you compile the C++ code using `TMB` and use that function in one of R's optimizers to find the minimum negative log likelihood. The beauty of `TMB` is that it uses the Laplace approximation to integrate over the states and computes the gradient efficiently, which speeds up the optimizing process.


Assuming you have properly installed \texttt{TMB}, let's load it.

```{R LoadTMB, message=FALSE}
library(TMB)
```

Now, let us create the negative log-likelihood function that we will minimize (equivalent of maximizing the likelihood). We write this function in a special TMB C++ language. The code for the function needs to be save in a text file. We usually give it the extension .cpp. You can do this directly in R Studio. You write the code just as you would write a separate R script, but you save it as a .cpp file by giving it the .cpp extension.

We name the file **toy2p.cpp** and it will contain the following code. Note that in C++, comments are preceded by \texttt{//} or contained within \texttt{/* */}. Also, as explained below, here the code is a little bit more complex than strictly necessary. We have included code that allow us to compute the one-step-ahead residuals and simulate from the model. While these features are not always necessary, they are key to model checking and thus we believe they should be part of all model fitting workflow.

```{Rcpp toy2p.cpp, eval=FALSE}
/*----------------------- SECTION A --------------------------*/
// Link to the TMB package
#include <TMB.hpp>

/*----------------------- SECTION B --------------------------*/
// Define main function
template<class Type>
Type objective_function<Type>::operator() ()
{

  /*----------------------- SECTION C --------------------------*/
  // Specify the input data
  DATA_VECTOR(y);

  // For one-step-ahead residuals
  DATA_VECTOR_INDICATOR(keep, y);

  // Specify the parameters
  PARAMETER(logSdP); // Log of st. dev. for the process variation
  PARAMETER(logSdO); // Log of st. dev. for the observation error

  // Specify the random effect/states
  PARAMETER_VECTOR(z);

  /*----------------------- SECTION D --------------------------*/
  // Transform standard deviations
  // exp(par) is a trick to make sure that the estimated sd > 0
  Type sdp = exp(logSdP);
  Type sdo = exp(logSdO);

  /*----------------------- SECTION E --------------------------*/
  // Define the variable that will keep track of
  // the negative log-likelihood (nll)
  Type nll = 0.0;

  /*----------------------- SECTION F --------------------------*/
  // Calculate the contribution to the negative log-likelihood
  // of the process equation for t=1,...,T
  // Remember that we fixed z_0 = 0
  for(int i = 1; i < z.size(); ++i){
    nll -= dnorm(z(i), z(i-1), sdp, true);

    //*----------------------- SECTION G --------------------------*/
    // Simulation block for process equation
    SIMULATE {
      z(i) = rnorm(z(i-1), sdp);
    }
  }

  /*----------------------- SECTION H --------------------------*/
  // Calculate the contribution to the negative log-likelihood
  // of the observation equation for t=1,...,T
  // Remember, the first element of z is at t=0,
  // while the first element of y is at t=1
  for(int i = 0; i < y.size(); ++i){
    nll -= keep(i)*dnorm(y(i), z(i+1), sdo, true);

    //*----------------------- SECTION I --------------------------*/
    // Simulation block for observation equation
    SIMULATE {
      y(i) = rnorm(z(i+1), sdo);
    }
  }


  /*----------------------- SECTION J --------------------------*/
  // State the transformed parameters to report
  // Using ADREPORT will return the point values and the standard errors
  // Note that we only need to specify this for parameters
  // we transformed, see section D above
  // The other parameters, including the random effects (states),
  // will be returned automatically
  ADREPORT(sdp);
  ADREPORT(sdo);

  /*----------------------- SECTION K --------------------------*/
  // Report simulated values
  SIMULATE{
    REPORT(z);
    REPORT(y);
  }


  /*----------------------- SECTION L --------------------------*/
  // State that we want the negative log-likelihood to be returned
  // This is what the optimizer in R will minimize
  return nll;

}

```
